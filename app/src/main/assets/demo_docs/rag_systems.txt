RAG системы (Retrieval-Augmented Generation)

RAG - это подход в искусственном интеллекте, который комбинирует поиск информации (Retrieval) и генерацию текста (Generation). RAG системы позволяют языковым моделям отвечать на вопросы на основе внешних документов.

Как работает RAG
1. Индексация документов - текст разбивается на чанки и создаются эмбеддинги
2. Поиск - по запросу пользователя находятся релевантные фрагменты
3. Формирование контекста - найденные фрагменты объединяются
4. Генерация ответа - LLM создаёт ответ на основе контекста

Векторные эмбеддинги
Эмбеддинг - это числовое представление текста в виде вектора. Семантически похожие тексты имеют похожие векторы.

Модели для эмбеддингов:
- OpenAI text-embedding-ada-002
- sentence-transformers (BERT-based)
- nomic-embed-text
- mxbai-embed-large

Векторные базы данных
Хранят эмбеддинги и позволяют быстро находить похожие векторы:
- Pinecone - облачная векторная БД
- Weaviate - open-source
- Chroma - легковесная
- FAISS - библиотека от Facebook
- Qdrant - на Rust

Метрики сходства
- Косинусное сходство - угол между векторами (самая популярная)
- Евклидово расстояние - геометрическое расстояние
- Dot product - скалярное произведение

Chunking (разбиение текста)
Способы разбиения документов на части:
1. По размеру - фиксированное количество символов
2. По предложениям - естественные границы
3. По параграфам - смысловые блоки
4. Рекурсивное - с перекрытием между чанками
5. Семантическое - по смыслу

Преимущества RAG
- Актуальность - работает с новыми данными без переобучения модели
- Точность - ответы основаны на реальных документах
- Прозрачность - можно показать источники
- Контроль - можно ограничить доступные документы
- Экономичность - не нужно fine-tuning больших моделей

Применения RAG
1. Корпоративные чат-боты - ответы на основе внутренней документации
2. Юридические ассистенты - поиск по законам и прецедентам
3. Медицинские системы - поиск по медицинской литературе
4. Техническая поддержка - ответы из базы знаний
5. Образовательные платформы - персонализированное обучение

Продвинутые техники
- Reranking - переранжирование результатов поиска
- Hybrid search - комбинация векторного и полнотекстового поиска
- Multi-query - несколько запросов для одного вопроса
- HyDE - гипотетические ответы для улучшения поиска
- Parent document retrieval - поиск по маленьким чанкам, возврат больших

Оценка качества RAG
Метрики:
- Relevance - релевантность найденных документов
- Faithfulness - соответствие ответа источникам
- Answer relevancy - релевантность ответа вопросу
- Context precision - точность контекста

Популярные фреймворки
- LangChain - фреймворк для LLM приложений
- LlamaIndex - специализируется на RAG
- Haystack - NLP фреймворк от deepset

Ollama для RAG
Ollama позволяет запускать LLM локально для RAG систем. Поддерживает модели:
- llama3 - для генерации ответов
- nomic-embed-text - для эмбеддингов
- mistral - быстрая генерация

Проблемы и решения
- Hallucinations - модель придумывает факты → использовать prompt engineering
- Irrelevant results - нерелевантные результаты → улучшить chunking и reranking
- Long context - слишком длинный контекст → сжатие и фильтрация
- Latency - медленная генерация → кеширование и streaming


