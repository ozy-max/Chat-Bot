Машинное обучение (Machine Learning)

Машинное обучение - подраздел искусственного интеллекта, изучающий методы обучения компьютеров без явного программирования. Модели обучаются на данных и делают предсказания.

Типы машинного обучения

Supervised Learning (Обучение с учителем)
Модель обучается на размеченных данных (вход + правильный ответ).

Задачи:
- Классификация - предсказание категории (спам/не спам, кот/собака)
- Регрессия - предсказание числового значения (цена дома, температура)

Алгоритмы:
- Линейная регрессия
- Логистическая регрессия
- Decision Trees
- Random Forest
- Support Vector Machines (SVM)
- K-Nearest Neighbors (KNN)
- Градиентный бустинг (XGBoost, LightGBM, CatBoost)

Unsupervised Learning (Обучение без учителя)
Модель ищет закономерности в неразмеченных данных.

Задачи:
- Кластеризация - группировка похожих объектов (сегментация клиентов)
- Снижение размерности - уменьшение количества признаков (PCA, t-SNE)
- Поиск аномалий - выявление выбросов

Алгоритмы:
- K-Means clustering
- DBSCAN
- Hierarchical clustering
- Principal Component Analysis (PCA)
- Autoencoders

Reinforcement Learning (Обучение с подкреплением)
Агент учится принимать решения через взаимодействие со средой. Получает награды за правильные действия.

Применения:
- Игры (AlphaGo, Dota 2 bots)
- Робототехника
- Автономные автомобили
- Торговые стратегии

Алгоритмы:
- Q-Learning
- Deep Q-Network (DQN)
- Policy Gradient
- Actor-Critic
- Proximal Policy Optimization (PPO)

Процесс машинного обучения

1. Сбор данных
Качество данных критически важно. "Garbage in - garbage out"

2. Подготовка данных
- Очистка - удаление дубликатов, обработка пропусков
- Feature Engineering - создание новых признаков
- Нормализация - приведение к одному масштабу
- Кодирование - преобразование категориальных данных

3. Разделение данных
- Train set (60-80%) - обучение модели
- Validation set (10-20%) - настройка гиперпараметров
- Test set (10-20%) - финальная оценка

4. Выбор модели
Зависит от задачи, размера данных, требований к интерпретируемости.

5. Обучение
Модель подбирает параметры минимизируя функцию потерь (loss function).

6. Оценка
Метрики качества:
- Классификация: Accuracy, Precision, Recall, F1-score, ROC-AUC
- Регрессия: MSE, RMSE, MAE, R²

7. Оптимизация
Подбор гиперпараметров, feature selection, ансамбли моделей.

Переобучение и недообучение

Overfitting (Переобучение)
Модель слишком хорошо запоминает обучающие данные, плохо работает на новых.

Признаки:
- Высокая точность на train, низкая на test
- Модель слишком сложная

Решения:
- Регуляризация (L1, L2)
- Dropout в нейронных сетях
- Больше данных
- Cross-validation
- Early stopping

Underfitting (Недообучение)
Модель слишком простая, не улавливает закономерности.

Признаки:
- Низкая точность и на train, и на test

Решения:
- Более сложная модель
- Больше признаков
- Уменьшить регуляризацию

Feature Engineering

Создание признаков
Преобразование сырых данных в признаки:
- Агрегации - среднее, сумма, max/min
- Временные признаки - день недели, час, сезон
- Комбинации - произведение, отношение признаков
- Полиномиальные признаки

Feature Selection
Выбор наиболее важных признаков:
- Correlation analysis
- Feature importance (Random Forest)
- Recursive Feature Elimination (RFE)
- LASSO регуляризация

Ансамбли

Bagging
Обучение нескольких моделей на разных подвыборках данных. Усреднение предсказаний. Пример: Random Forest.

Boosting
Последовательное обучение моделей, каждая исправляет ошибки предыдущей. Примеры: AdaBoost, Gradient Boosting, XGBoost.

Stacking
Использование предсказаний базовых моделей как признаков для мета-модели.

Cross-Validation
K-Fold CV разбивает данные на K частей. Обучает K моделей, каждая тестируется на своей части. Усредняет результаты.

Популярные библиотеки

Scikit-learn
Универсальная библиотека для ML в Python. Содержит алгоритмы классификации, регрессии, кластеризации, preprocessing.

XGBoost
Оптимизированный градиентный бустинг. Победитель многих соревнований Kaggle.

LightGBM
Быстрый градиентный бустинг от Microsoft. Эффективен для больших данных.

CatBoost
Градиентный бустинг от Yandex. Хорошо работает с категориальными признаками.

TensorFlow / PyTorch
Фреймворки для глубокого обучения.

AutoML
Автоматизация ML пайплайна:
- Google AutoML
- H2O.ai
- Auto-sklearn
- TPOT

Transfer Learning
Использование предобученных моделей. Дообучение (fine-tuning) на своих данных. Экономит время и вычислительные ресурсы.

Примеры:
- Компьютерное зрение: ResNet, VGG, EfficientNet
- NLP: BERT, GPT, T5

MLOps
Практики для продакшен ML систем:
- Версионирование данных и моделей
- CI/CD для ML
- Мониторинг моделей в продакшене
- A/B тестирование
- Переобучение моделей

Инструменты: MLflow, Kubeflow, DVC, Weights & Biases.

Этика и ответственность
- Bias в данных и моделях
- Fairness - справедливость предсказаний
- Explainability - интерпретируемость решений
- Privacy - защита данных пользователей
- GDPR и право на объяснение решений AI

Будущее ML
- Federated Learning - обучение без централизации данных
- Quantum Machine Learning - ML на квантовых компьютерах
- Neural Architecture Search - автоматический поиск архитектур
- Few-shot Learning - обучение на малом количестве примеров
- Continual Learning - непрерывное обучение без забывания

